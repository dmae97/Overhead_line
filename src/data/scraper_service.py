"""ë¸Œë¼ìš°ì € ìë™í™” ìŠ¤í¬ë˜í¼ í†µí•© ì„œë¹„ìŠ¤ â€” í•œì „ON(EWM092D00) ìš°ì„ , ê¸°ì¡´ Playwright/Selenium í´ë°±.

API í‚¤ê°€ ì—†ì„ ë•Œ í•œì „ON ì ‘ì†ê°€ëŠ¥ ìš©ëŸ‰ì¡°íšŒë¥¼ ë¸Œë¼ìš°ì € ìë™í™”ë¡œ ìˆ˜í–‰í•œë‹¤.
ì—”ì§„ ìš°ì„ ìˆœìœ„:
  1. í•œì „ON EWM092D00 (online.kepco.co.kr â€” Playwright ê¸°ë°˜, ì£¼ì†Œ cascading)
  2. Playwright ê¸°ì¡´ (home.kepco.co.kr â€” í‚¤ì›Œë“œ ê²€ìƒ‰, ë´‡íƒì§€ ê°€ëŠ¥ì„± ìˆìŒ)
  3. Selenium (ë ˆê±°ì‹œ í´ë°±)

ì„¤ì •:
  - SCRAPER_ENGINE í™˜ê²½ë³€ìˆ˜ë¡œ 1ì°¨ ì—”ì§„ ì§€ì • (ê¸°ë³¸ "playwright")
  - 1ì°¨ ì—”ì§„ ì‹¤íŒ¨ ì‹œ ìë™ìœ¼ë¡œ ë‚˜ë¨¸ì§€ ì—”ì§„ì„ í´ë°± ì‹œë„
  - ê° ì—”ì§„ì€ ìµœëŒ€ MAX_RETRIESíšŒ ì¬ì‹œë„ (ë´‡ íƒì§€ ë“± ì¼ì‹œì  ì‹¤íŒ¨ ëŒ€ì‘)
"""

from __future__ import annotations

import logging
import time
from typing import Literal

from src.core.config import settings
from src.core.exceptions import ScraperError
from src.data.models import CapacityRecord

logger = logging.getLogger(__name__)

EngineType = Literal["playwright", "selenium"]

# ì—”ì§„ë‹¹ ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ (ì²« ì‹œë„ í¬í•¨)
MAX_RETRIES = 2
# ì¬ì‹œë„ ì‚¬ì´ ëŒ€ê¸° ì‹œê°„ (ì´ˆ)
RETRY_DELAY_SECONDS = 3.0

# ì—”ì§„ë³„ ì§€ì—° import + ì‹¤í–‰ì„ ë‹´ë‹¹í•˜ëŠ” ë‚´ë¶€ í•¨ìˆ˜
# (ê° íŒ¨í‚¤ì§€ê°€ ë¯¸ì„¤ì¹˜ì—¬ë„ import ì‹œì ì— ì•±ì´ ì£½ì§€ ì•Šë„ë¡ lazy import)


def _run_kepco_online(
    keyword: str,
    sido: str = "",
    sigungu: str = "",
    dong: str = "",
    jibun: str = "",
) -> list[CapacityRecord]:
    """í•œì „ON EWM092D00 (online.kepco.co.kr) Playwright ì—”ì§„ìœ¼ë¡œ ìš©ëŸ‰ ì¡°íšŒ.

    keywordëŠ” í˜¸í™˜ì„±ì„ ìœ„í•´ ë°›ì§€ë§Œ, sido/sigungu/dongì´ ì œê³µë˜ë©´ ìš°ì„  ì‚¬ìš©í•œë‹¤.
    """
    from src.data.kepco_online import KepcoOnlineScraper

    scraper = KepcoOnlineScraper()
    if sido:
        return scraper.fetch_capacity_by_region(sido=sido, sigungu=sigungu, dong=dong, jibun=jibun)
    # keywordë§Œ ì œê³µëœ ê²½ìš° â€” íŒŒì‹± ì‹œë„ (ì‹œë„ëª… ì¶”ì¶œ)
    # "ì¶©ì²­ë‚¨ë„ ì²œì•ˆì‹œ ì„œë¶êµ¬ ë¶ˆë‹¹ë™ 142-1" ê°™ì€ í˜•íƒœ
    parts = keyword.strip().split()
    if parts:
        return scraper.fetch_capacity(
            sido=parts[0],
            si=parts[1] if len(parts) > 1 else "",
            gu=parts[2] if len(parts) > 2 else "",
            dong=parts[3] if len(parts) > 3 else "",
            jibun=parts[4] if len(parts) > 4 else "",
        )
    raise ScraperError("ê²€ìƒ‰ í‚¤ì›Œë“œê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")


def _run_playwright(keyword: str) -> list[CapacityRecord]:
    """Playwright ì—”ì§„ìœ¼ë¡œ ìš©ëŸ‰ ì¡°íšŒ (ê¸°ì¡´ home.kepco.co.kr)."""
    from src.data.kepco_playwright import KepcoPlaywrightScraper

    scraper = KepcoPlaywrightScraper()
    return scraper.fetch_capacity_by_keyword(keyword)


def _run_selenium(keyword: str) -> list[CapacityRecord]:
    """Selenium ì—”ì§„ìœ¼ë¡œ ìš©ëŸ‰ ì¡°íšŒ."""
    from src.data.kepco_scraper import KepcoCapacityScraper

    scraper = KepcoCapacityScraper()
    return scraper.fetch_capacity_by_keyword(keyword)


def _resolve_engine_order() -> list[EngineType]:
    """ì„¤ì •ì— ë”°ë¼ (1ì°¨ ì—”ì§„, í´ë°± ì—”ì§„) ìˆœì„œë¥¼ ê²°ì •.

    Returns:
        [primary, fallback] ìˆœì„œì˜ ì—”ì§„ ì´ë¦„ ë¦¬ìŠ¤íŠ¸.
    """
    primary: EngineType = (
        "selenium" if settings.scraper_engine.strip().lower() == "selenium" else "playwright"
    )
    fallback: EngineType = "selenium" if primary == "playwright" else "playwright"
    return [primary, fallback]


def _get_runner(engine_name: EngineType):
    """ì—”ì§„ ì´ë¦„ì— í•´ë‹¹í•˜ëŠ” ì‹¤í–‰ í•¨ìˆ˜ë¥¼ ë°˜í™˜.

    ëª¨ë“ˆ ë ˆë²¨ì˜ _run_playwright / _run_seleniumì„ **ëŸ°íƒ€ì„ì—** ì°¸ì¡°í•˜ë¯€ë¡œ
    unittest.mock.patchì™€ í˜¸í™˜ëœë‹¤.
    """
    if engine_name == "selenium":
        return _run_selenium
    return _run_playwright


def _run_engine_with_retry(
    engine_name: EngineType,
    keyword: str,
) -> list[CapacityRecord]:
    """ë‹¨ì¼ ì—”ì§„ì„ ìµœëŒ€ MAX_RETRIESíšŒ ì¬ì‹œë„í•˜ë©° ì‹¤í–‰.

    ì²« ì‹œë„ ì‹¤íŒ¨ ì‹œ RETRY_DELAY_SECONDSë§Œí¼ ëŒ€ê¸° í›„ ì¬ì‹œë„í•œë‹¤.
    ImportError ë“± ì„¤ì¹˜ ë¬¸ì œëŠ” ì¬ì‹œë„ ì˜ë¯¸ê°€ ì—†ìœ¼ë¯€ë¡œ ì¦‰ì‹œ í¬ê¸°.
    """
    runner = _get_runner(engine_name)
    last_exc: Exception | None = None

    for attempt in range(1, MAX_RETRIES + 1):
        try:
            logger.info(
                "ğŸš€ [%s] ì—”ì§„ ì‹œë„ %d/%d: %s",
                engine_name,
                attempt,
                MAX_RETRIES,
                keyword,
            )
            records = runner(keyword)
            logger.info(
                "âœ… [%s] ì—”ì§„ ì¡°íšŒ ì„±ê³µ â€” %dê±´ ë°˜í™˜",
                engine_name,
                len(records),
            )
            return records
        except ScraperError as exc:
            last_exc = exc
            # ì„¤ì¹˜ ë¬¸ì œ(Import ê´€ë ¨)ëŠ” ì¬ì‹œë„ ë¬´ì˜ë¯¸
            if "ì„¤ì¹˜" in exc.message or "import" in exc.message.lower():
                logger.warning(
                    "âš ï¸ [%s] ì„¤ì¹˜ ë¬¸ì œë¡œ ì¦‰ì‹œ í¬ê¸°: %s",
                    engine_name,
                    exc.message[:200],
                )
                break
            logger.warning(
                "âš ï¸ [%s] ì‹œë„ %d ì‹¤íŒ¨: %s",
                engine_name,
                attempt,
                exc.message[:200],
            )
        except Exception as exc:
            last_exc = exc
            logger.warning(
                "âš ï¸ [%s] ì‹œë„ %d ì˜ˆì™¸: %s: %s",
                engine_name,
                attempt,
                type(exc).__name__,
                str(exc)[:200],
            )

        # ì¬ì‹œë„ ì „ ëŒ€ê¸° (ë§ˆì§€ë§‰ ì‹œë„ í›„ì—ëŠ” ë¶ˆí•„ìš”)
        if attempt < MAX_RETRIES:
            logger.info(
                "â³ [%s] %.1fì´ˆ í›„ ì¬ì‹œë„...",
                engine_name,
                RETRY_DELAY_SECONDS,
            )
            time.sleep(RETRY_DELAY_SECONDS)

    # ëª¨ë“  ì¬ì‹œë„ ì†Œì§„
    assert last_exc is not None
    raise last_exc


def fetch_capacity_by_browser(keyword: str) -> list[CapacityRecord]:
    """Playwright ìš°ì„  â†’ Selenium í´ë°±ìœ¼ë¡œ ìš©ëŸ‰ ì¡°íšŒë¥¼ ì‹œë„.

    ê° ì—”ì§„ì€ ë‚´ë¶€ì ìœ¼ë¡œ ìµœëŒ€ MAX_RETRIESíšŒ ì¬ì‹œë„í•œë‹¤.

    Args:
        keyword: ê²€ìƒ‰í•  ì£¼ì†Œ í‚¤ì›Œë“œ (ì˜ˆ: "ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ ì¡°ì¹˜ì›ì 142-1")

    Returns:
        CapacityRecord ë¦¬ìŠ¤íŠ¸

    Raises:
        ScraperError: ëª¨ë“  ì—”ì§„ì´ ì‹¤íŒ¨í•œ ê²½ìš°
    """
    engines = _resolve_engine_order()
    errors: list[tuple[str, Exception]] = []

    for engine_name in engines:
        try:
            return _run_engine_with_retry(engine_name, keyword)
        except ScraperError as exc:
            errors.append((engine_name, exc))
        except Exception as exc:
            errors.append((engine_name, exc))

    # ëª¨ë“  ì—”ì§„ì´ ì‹¤íŒ¨í•œ ê²½ìš° â€” ì—ëŸ¬ ìš”ì•½ ë©”ì‹œì§€ ìƒì„±
    summary_lines = ["ëª¨ë“  ë¸Œë¼ìš°ì € ìë™í™” ì—”ì§„ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."]
    for engine_name, exc in errors:
        msg = getattr(exc, "message", str(exc))
        summary_lines.append(f"  - {engine_name}: {msg}")
    summary_lines.append(
        "í•´ê²°: Playwright(`uv add playwright && playwright install chromium`) ë˜ëŠ” "
        "Selenium(`uv add selenium`) ì„¤ì¹˜ë¥¼ í™•ì¸í•˜ì„¸ìš”."
    )

    raise ScraperError("\n".join(summary_lines))


def fetch_capacity_by_online(
    sido: str,
    sigungu: str,
    dong: str = "",
    jibun: str = "",
) -> list[CapacityRecord]:
    """í•œì „ON(EWM092D00) Playwright ìŠ¤í¬ë˜í¼ë¡œ ì§ì ‘ ìš©ëŸ‰ ì¡°íšŒ.

    API í‚¤ ì—†ì´ ì‚¬ìš© ê°€ëŠ¥. ì£¼ì†Œ ê¸°ë°˜ cascading ì„ íƒ í›„ DOMì—ì„œ ê²°ê³¼ë¥¼ íŒŒì‹±.

    Args:
        sido: ì‹œ/ë„ (ì˜ˆ: "ì¶©ì²­ë‚¨ë„")
        sigungu: ì‹œêµ°êµ¬ (ì˜ˆ: "ì²œì•ˆì‹œ ì„œë¶êµ¬")
        dong: ì/ë©´/ë™ (ì˜ˆ: "ë¶ˆë‹¹ë™")
        jibun: ë²ˆì§€ (ì„ íƒ)

    Returns:
        CapacityRecord ë¦¬ìŠ¤íŠ¸

    Raises:
        ScraperError: ë¸Œë¼ìš°ì € ìë™í™” ì‹¤íŒ¨
    """
    last_exc: Exception | None = None

    for attempt in range(1, MAX_RETRIES + 1):
        try:
            logger.info(
                "ğŸš€ [kepco_online] ì‹œë„ %d/%d: %s %s %s",
                attempt,
                MAX_RETRIES,
                sido,
                sigungu,
                dong,
            )
            records = _run_kepco_online(
                keyword="",
                sido=sido,
                sigungu=sigungu,
                dong=dong,
                jibun=jibun,
            )
            logger.info(
                "âœ… [kepco_online] ì¡°íšŒ ì„±ê³µ â€” %dê±´ ë°˜í™˜",
                len(records),
            )
            return records
        except ScraperError as exc:
            last_exc = exc
            if "ì„¤ì¹˜" in exc.message or "import" in exc.message.lower():
                break
            logger.warning(
                "âš ï¸ [kepco_online] ì‹œë„ %d ì‹¤íŒ¨: %s",
                attempt,
                exc.message[:200],
            )
        except Exception as exc:
            last_exc = exc
            logger.warning(
                "âš ï¸ [kepco_online] ì‹œë„ %d ì˜ˆì™¸: %s",
                attempt,
                str(exc)[:200],
            )

        if attempt < MAX_RETRIES:
            time.sleep(RETRY_DELAY_SECONDS)

    assert last_exc is not None
    raise last_exc
