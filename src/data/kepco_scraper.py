"""í•œì „ Selenium í´ë°± ìŠ¤í¬ë˜í¼ â€” online.kepco.co.kr ìœ„ì„ ë˜í¼.

ê¸°ì¡´ì—ëŠ” home.kepco.co.kr ì ‘ì†ê°€ëŠ¥ ìš©ëŸ‰ì¡°íšŒ í˜ì´ì§€ë¥¼ Seleniumìœ¼ë¡œ ìŠ¤í¬ë˜í•‘í–ˆìœ¼ë‚˜,
í•œì „ì´ í•´ë‹¹ í˜ì´ì§€ë¥¼ ë³€ê²½í•˜ì—¬ ì—¬ìœ ìš©ëŸ‰ ë°ì´í„°ê°€ ë” ì´ìƒ ì œê³µë˜ì§€ ì•ŠëŠ”ë‹¤.

í˜„ì¬ ì´ ëª¨ë“ˆì€ í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€ë˜ë©°,
ë‚´ë¶€ì ìœ¼ë¡œ KepcoOnlineScraper(online.kepco.co.kr)ì— ìœ„ì„í•œë‹¤.
"""

from __future__ import annotations

import logging
from dataclasses import dataclass

from src.core.exceptions import ScraperError
from src.data.models import CapacityRecord

logger = logging.getLogger(__name__)


@dataclass(frozen=True)
class ScrapeOptions:
    """Selenium ìŠ¤í¬ë˜í¼ ì˜µì…˜ (í˜¸í™˜ì„± ìœ ì§€)."""

    headless: bool = True
    page_load_timeout_seconds: float = 40.0
    result_timeout_seconds: float = 30.0


def _parse_keyword_to_region(keyword: str) -> dict[str, str]:
    """í‚¤ì›Œë“œ ë¬¸ìì—´ì„ sido/si/gu/dong/jibunìœ¼ë¡œ íŒŒì‹± ì‹œë„."""
    parts = keyword.strip().split()
    if not parts:
        raise ScraperError("ê²€ìƒ‰ í‚¤ì›Œë“œê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")

    result = {"sido": "", "si": "", "gu": "", "dong": "", "jibun": ""}
    result["sido"] = parts[0]

    if len(parts) >= 2:
        token = parts[1]
        if any(token.endswith(s) for s in ["ì‹œ", "êµ°"]):
            result["si"] = token
        elif any(token.endswith(s) for s in ["êµ¬"]):
            result["gu"] = token
        elif any(token.endswith(s) for s in ["ì", "ë©´", "ë™", "ë¦¬", "ë¡œ", "ê¸¸"]):
            result["dong"] = token
        else:
            result["si"] = token

    if len(parts) >= 3:
        token = parts[2]
        if any(token.endswith(s) for s in ["êµ¬", "êµ°"]):
            result["gu"] = token
        elif any(token.endswith(s) for s in ["ì", "ë©´", "ë™", "ë¦¬", "ë¡œ", "ê¸¸"]):
            result["dong"] = token
        else:
            if not result["gu"]:
                result["gu"] = token
            else:
                result["dong"] = token

    if len(parts) >= 4:
        token = parts[3]
        if any(token.endswith(s) for s in ["ì", "ë©´", "ë™", "ë¦¬", "ë¡œ", "ê¸¸"]) or not result["dong"]:
            result["dong"] = token
        else:
            result["jibun"] = token

    if len(parts) >= 5 and not result["jibun"]:
        result["jibun"] = " ".join(parts[4:])

    return result


class KepcoCapacityScraper:
    """Selenium ê¸°ë°˜ í•œì „ ì ‘ì†ê°€ëŠ¥ ìš©ëŸ‰ì¡°íšŒ ìŠ¤í¬ë˜í¼.

    ë‚´ë¶€ì ìœ¼ë¡œ KepcoOnlineScraperì— ìœ„ì„í•œë‹¤.
    """

    def __init__(self, url: str | None = None, options: ScrapeOptions | None = None) -> None:
        self._url = url
        self._options = options or ScrapeOptions()

    def fetch_capacity_by_keyword(self, keyword: str) -> list[CapacityRecord]:
        """í‚¤ì›Œë“œë¡œ ê²€ìƒ‰ í›„ ì—¬ìœ ìš©ëŸ‰ ë ˆì½”ë“œë¥¼ ë°˜í™˜."""
        from src.data.kepco_online import KepcoOnlineScraper

        logger.info("ğŸ”„ Selenium ë˜í¼: í‚¤ì›Œë“œ '%s' â†’ KepcoOnlineScraper ìœ„ì„", keyword)
        region = _parse_keyword_to_region(keyword)
        logger.info("ğŸ“ í‚¤ì›Œë“œ íŒŒì‹± ê²°ê³¼: %s", region)

        scraper = KepcoOnlineScraper()
        return scraper.fetch_capacity(
            sido=region["sido"],
            si=region["si"],
            gu=region["gu"],
            dong=region["dong"],
            jibun=region["jibun"],
        )
