"""í•œì „ í™ˆí˜ì´ì§€ ê¸°ë°˜ Playwright í—¤ë“œë¦¬ìŠ¤ ìŠ¤í¬ë˜í¼.

Selenium í´ë°±(`kepco_scraper.py`) ëŒ€ë¹„ ì¥ì :
- ë„¤ì´í‹°ë¸Œ response ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆ (CDP ëª…ë ¹ ë¶ˆí•„ìš”)
- ìë™ ëŒ€ê¸° (explicit WebDriverWait ë¶ˆí•„ìš”)
- ë” ë‚˜ì€ stealth (navigator.webdriver ê¸°ë³¸ ìš°íšŒ)
- Chromium ì™¸ Firefox/WebKitë„ ì§€ì› ê°€ëŠ¥
- ê²½ëŸ‰í•œ headless ëª¨ë“œ

ì „ëµ:
- page.on("response") ì´ë²¤íŠ¸ë¡œ JSON ì‘ë‹µì„ ì‹¤ì‹œê°„ ìº¡ì²˜
- vol1/vol2/vol3 í‚¤ê°€ í¬í•¨ëœ ì‘ë‹µì„ íƒì§€í•˜ë©´ íŒŒì‹±
- ì£¼ì†Œ/í‚¤ì›Œë“œ ì…ë ¥ + ê²€ìƒ‰ íŠ¸ë¦¬ê±° í›„ ê²°ê³¼ ëŒ€ê¸°
"""

from __future__ import annotations

import json
import logging
import threading
from dataclasses import dataclass, field
from typing import Any

from src.core.config import settings
from src.core.exceptions import ScraperError
from src.data.models import CapacityRecord

logger = logging.getLogger(__name__)


def _extract_records(payload: Any) -> list[dict[str, Any]]:
    """API ì‘ë‹µ í˜ì´ë¡œë“œì—ì„œ ë ˆì½”ë“œ ë¦¬ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œ."""
    if isinstance(payload, dict):
        data = payload.get("data")
        if isinstance(data, list):
            return [d for d in data if isinstance(d, dict)]
    if isinstance(payload, list):
        return [d for d in payload if isinstance(d, dict)]
    return []


def _looks_like_capacity_payload(text: str) -> bool:
    """ë¹ ë¥¸ íŒíŠ¸: ì‘ë‹µì— vol1/vol2/vol3ê°€ í¬í•¨ë˜ë©´ ìš©ëŸ‰ ì‘ë‹µì¼ í™•ë¥ ì´ ë†’ë‹¤."""
    return '"vol1"' in text and '"vol2"' in text and '"vol3"' in text


@dataclass(frozen=True)
class PlaywrightOptions:
    """Playwright ìŠ¤í¬ë˜í¼ ì‹¤í–‰ ì˜µì…˜."""

    headless: bool = field(default_factory=lambda: settings.playwright_headless)
    page_load_timeout_ms: int = field(
        default_factory=lambda: int(settings.playwright_page_load_timeout_seconds * 1000)
    )
    result_timeout_ms: int = field(
        default_factory=lambda: int(settings.playwright_result_timeout_seconds * 1000)
    )
    browser_type: str = field(default_factory=lambda: settings.playwright_browser_type)


class KepcoPlaywrightScraper:
    """Playwright ê¸°ë°˜ í•œì „ ì ‘ì†ê°€ëŠ¥ ìš©ëŸ‰ì¡°íšŒ ìŠ¤í¬ë˜í¼.

    ì‚¬ìš© ì˜ˆì‹œ::

        scraper = KepcoPlaywrightScraper()
        records = scraper.fetch_capacity_by_keyword("ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ ì¡°ì¹˜ì›ì")
        for r in records:
            print(f"{r.dl_nm}: {r.min_capacity} kW")
    """

    def __init__(
        self,
        url: str | None = None,
        options: PlaywrightOptions | None = None,
    ) -> None:
        self._url = url or settings.kepco_on_capacity_url
        self._options = options or PlaywrightOptions()

    def fetch_capacity_by_keyword(self, keyword: str) -> list[CapacityRecord]:
        """í‚¤ì›Œë“œ(ì£¼ì†Œ/ì§€ë²ˆ ë“±)ë¡œ ê²€ìƒ‰ í›„ ì—¬ìœ ìš©ëŸ‰ ë ˆì½”ë“œë¥¼ ë°˜í™˜.

        Args:
            keyword: ê²€ìƒ‰í•  ì£¼ì†Œ í‚¤ì›Œë“œ (ì˜ˆ: "ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ ì¡°ì¹˜ì›ì")

        Returns:
            CapacityRecord ë¦¬ìŠ¤íŠ¸

        Raises:
            ScraperError: ë¸Œë¼ìš°ì € ìë™í™” ì‹¤íŒ¨, ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨ ë“±
        """
        try:
            from playwright.sync_api import sync_playwright
        except ImportError as exc:
            raise ScraperError(
                "playwright íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.\n"
                "ì„¤ì¹˜: `pip install playwright && playwright install chromium`\n"
                "ë˜ëŠ”: `uv add playwright && playwright install chromium`"
            ) from exc

        # ìº¡ì²˜ëœ ìš©ëŸ‰ ë°ì´í„°ë¥¼ ì €ì¥í•  ì»¨í…Œì´ë„ˆ
        captured_payload: list[Any] = []
        payload_lock = threading.Lock()

        def _on_response(response):
            """Network ì‘ë‹µ ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ â€” vol1/vol2/vol3 í¬í•¨ JSON íƒì§€."""
            try:
                content_type = response.headers.get("content-type", "")
                # JSON ì‘ë‹µ ë˜ëŠ” text/html(ì¼ë¶€ í•œì „ ì‘ë‹µ)ì„ ëŒ€ìƒìœ¼ë¡œ
                if response.status != 200:
                    return

                body = response.text()
                if not body or not _looks_like_capacity_payload(body):
                    return

                data = json.loads(body)
                with payload_lock:
                    if not captured_payload:
                        captured_payload.append(data)
                        logger.info(
                            "âœ… ìš©ëŸ‰ ì‘ë‹µ ìº¡ì²˜ ì„±ê³µ (URL: %s, size: %d bytes)",
                            response.url[:80],
                            len(body),
                        )
            except Exception:
                # JSON íŒŒì‹± ì‹¤íŒ¨ ë“±ì€ ë¬´ì‹œ (ë‹¤ë¥¸ ì‘ë‹µ ê³„ì† íƒìƒ‰)
                pass

        with sync_playwright() as pw:
            browser = None
            try:
                browser = self._launch_browser(pw)
                context = browser.new_context(
                    viewport={"width": 1400, "height": 900},
                    locale="ko-KR",
                    # navigator.webdriver ìš°íšŒë¥¼ ìœ„í•œ ìŠ¤í…”ìŠ¤
                    extra_http_headers={
                        "Accept-Language": "ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7",
                    },
                )

                # ìë™í™” ê°ì§€ ìš°íšŒ: navigator.webdriver í”Œë˜ê·¸ ì œê±°
                context.add_init_script("""
                    Object.defineProperty(navigator, 'webdriver', {
                        get: () => undefined
                    });
                    // Chrome ìë™í™” ê°ì§€ ì™„í™”
                    window.chrome = { runtime: {} };
                    Object.defineProperty(navigator, 'plugins', {
                        get: () => [1, 2, 3, 4, 5]
                    });
                    Object.defineProperty(navigator, 'languages', {
                        get: () => ['ko-KR', 'ko', 'en-US', 'en']
                    });
                """)

                page = context.new_page()
                page.set_default_timeout(self._options.page_load_timeout_ms)

                # ì‘ë‹µ ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆ ë“±ë¡
                page.on("response", _on_response)

                logger.info("ğŸ“¡ í•œì „ ì ‘ì†ê°€ëŠ¥ ìš©ëŸ‰ì¡°íšŒ í˜ì´ì§€ ë¡œë”©: %s", self._url)
                page.goto(self._url, wait_until="domcontentloaded")
                logger.info("âœ… í˜ì´ì§€ ë¡œë“œ ì™„ë£Œ")

                # ê²€ìƒ‰ ì‹¤í–‰
                self._trigger_search(page, keyword)

                # ìš©ëŸ‰ ì‘ë‹µ ëŒ€ê¸°
                self._wait_for_capacity_payload(page, captured_payload, payload_lock)

                with payload_lock:
                    if not captured_payload:
                        raise ScraperError(
                            "ìš©ëŸ‰ ì‘ë‹µì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. "
                            "ì‚¬ì´íŠ¸ê°€ CAPTCHA/ë´‡íƒì§€ë¥¼ ìš”êµ¬í•˜ê±°ë‚˜ DOMì´ ë³€ê²½ë˜ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                        )
                    payload = captured_payload[0]

                raw = _extract_records(payload)
                if not raw:
                    raise ScraperError("ìš©ëŸ‰ ë°ì´í„° íŒŒì‹± ì‹¤íŒ¨ (dataê°€ ë¹„ì–´ìˆìŒ)")

                records: list[CapacityRecord] = []
                for item in raw:
                    try:
                        records.append(CapacityRecord(**item))
                    except Exception:
                        continue

                if not records:
                    raise ScraperError("ìš©ëŸ‰ ë°ì´í„° íŒŒì‹± ì‹¤íŒ¨ (ìœ íš¨ ë ˆì½”ë“œ 0ê±´)")

                logger.info("âœ… %dê±´ì˜ ì—¬ìœ ìš©ëŸ‰ ë ˆì½”ë“œ íŒŒì‹± ì™„ë£Œ", len(records))
                return records

            except ScraperError:
                raise
            except Exception as exc:
                logger.exception("Playwright ìŠ¤í¬ë˜í•‘ ì‹¤íŒ¨")
                raise ScraperError(f"ë¸Œë¼ìš°ì € ìë™í™” ì˜¤ë¥˜: {type(exc).__name__}: {exc}") from exc
            finally:
                if browser:
                    try:
                        browser.close()
                    except Exception:
                        pass

    def _launch_browser(self, pw):
        """Playwright ë¸Œë¼ìš°ì € ì¸ìŠ¤í„´ìŠ¤ ì‹¤í–‰."""
        browser_type_name = self._options.browser_type.lower()

        if browser_type_name == "firefox":
            launcher = pw.firefox
        elif browser_type_name == "webkit":
            launcher = pw.webkit
        else:
            launcher = pw.chromium

        logger.info(
            "ğŸš€ Playwright %s ë¸Œë¼ìš°ì € ì‹œì‘ (headless=%s)",
            browser_type_name,
            self._options.headless,
        )

        return launcher.launch(
            headless=self._options.headless,
            args=[
                "--no-sandbox",
                "--disable-dev-shm-usage",
                "--disable-blink-features=AutomationControlled",
            ]
            if browser_type_name == "chromium"
            else [],
        )

    def _trigger_search(self, page, keyword: str) -> None:
        """ê²€ìƒ‰ ì…ë ¥ì°½ì— í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ê³  ê²€ìƒ‰ì„ íŠ¸ë¦¬ê±°."""
        logger.info("ğŸ” ê²€ìƒ‰ í‚¤ì›Œë“œ: %s", keyword)

        # ì…ë ¥ì°½ ëŒ€ê¸° ë° ì…ë ¥
        try:
            # í•œì „ ì ‘ì†ê°€ëŠ¥ ìš©ëŸ‰ì¡°íšŒ í˜ì´ì§€ì˜ ê²€ìƒ‰ ì…ë ¥ì°½
            # ì—¬ëŸ¬ ê°€ëŠ¥í•œ ì…€ë ‰í„°ë¥¼ ìˆœì„œëŒ€ë¡œ ì‹œë„
            input_selectors = [
                "#inpSearchKeyword",
                "input[name='searchKeyword']",
                "input[type='text']",
            ]

            input_elem = None
            for selector in input_selectors:
                try:
                    input_elem = page.wait_for_selector(
                        selector,
                        timeout=10000,
                        state="visible",
                    )
                    if input_elem:
                        logger.info("âœ… ì…ë ¥ì°½ ë°œê²¬: %s", selector)
                        break
                except Exception:
                    continue

            if not input_elem:
                # í˜ì´ì§€ ìŠ¤í¬ë¦°ìƒ·ìœ¼ë¡œ ë””ë²„ê¹… íŒíŠ¸ ì œê³µ
                logger.warning("ê²€ìƒ‰ ì…ë ¥ì°½ì„ ì°¾ì§€ ëª»í•¨. í˜„ì¬ URL: %s", page.url)
                raise ScraperError(
                    "ê²€ìƒ‰ ì…ë ¥ì°½ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. "
                    "í˜ì´ì§€ êµ¬ì¡°ê°€ ë³€ê²½ë˜ì—ˆê±°ë‚˜ ë´‡ ê°ì§€ë¡œ ì°¨ë‹¨ë˜ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                )

            # ê¸°ì¡´ í…ìŠ¤íŠ¸ ì œê±° í›„ í‚¤ì›Œë“œ ì…ë ¥
            input_elem.click()
            input_elem.fill("")
            input_elem.fill(keyword)

            # ê²€ìƒ‰ ë²„íŠ¼ í´ë¦­ ì‹œë„
            search_triggered = False
            button_selectors = [
                "#btn_search",
                "button[type='submit']",
                "button:has-text('ê²€ìƒ‰')",
                "a:has-text('ê²€ìƒ‰')",
                ".btn_search",
            ]

            for selector in button_selectors:
                try:
                    btn = page.wait_for_selector(selector, timeout=3000, state="visible")
                    if btn:
                        btn.click()
                        search_triggered = True
                        logger.info("âœ… ê²€ìƒ‰ ë²„íŠ¼ í´ë¦­: %s", selector)
                        break
                except Exception:
                    continue

            # ë²„íŠ¼ì„ ëª» ì°¾ìœ¼ë©´ Enter í‚¤ë¡œ ê²€ìƒ‰
            if not search_triggered:
                logger.info("ê²€ìƒ‰ ë²„íŠ¼ ë¯¸ë°œê²¬ â†’ Enter í‚¤ë¡œ ê²€ìƒ‰ íŠ¸ë¦¬ê±°")
                input_elem.press("Enter")

        except ScraperError:
            raise
        except Exception as exc:
            raise ScraperError(f"ê²€ìƒ‰ íŠ¸ë¦¬ê±° ì‹¤íŒ¨: {exc}") from exc

    def _wait_for_capacity_payload(
        self,
        page,
        captured_payload: list[Any],
        payload_lock: threading.Lock,
    ) -> None:
        """ìš©ëŸ‰ ì‘ë‹µì´ ìº¡ì²˜ë  ë•Œê¹Œì§€ ëŒ€ê¸°."""
        import time

        timeout_seconds = self._options.result_timeout_ms / 1000.0
        end_time = time.time() + timeout_seconds
        poll_interval = 0.3  # 300ms ê°„ê²©ìœ¼ë¡œ í´ë§

        logger.info("â³ ìš©ëŸ‰ ì‘ë‹µ ëŒ€ê¸° ì¤‘... (ìµœëŒ€ %.0fì´ˆ)", timeout_seconds)

        while time.time() < end_time:
            with payload_lock:
                if captured_payload:
                    return

            # í˜ì´ì§€ ì´ë²¤íŠ¸ ì²˜ë¦¬ë¥¼ ìœ„í•´ ì ì‹œ ëŒ€ê¸°
            try:
                page.wait_for_timeout(int(poll_interval * 1000))
            except Exception:
                time.sleep(poll_interval)

        # íƒ€ì„ì•„ì›ƒ ë„ë‹¬
        logger.warning("â° ìš©ëŸ‰ ì‘ë‹µ ëŒ€ê¸° ì‹œê°„ ì´ˆê³¼ (%.0fì´ˆ)", timeout_seconds)
